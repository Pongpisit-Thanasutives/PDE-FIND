{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e4730cb",
   "metadata": {},
   "source": [
    "# PDE-FIND for the Kuramoto Sivashinsky Equation\n",
    "\n",
    "This notebook demonstrates PDE-FIND on the Kuramoto Sivashinsky equation.\n",
    "$$\n",
    "u_t + u_{xxxx} + uu_x + u_{xx} = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc63748a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn's version: 1.2.2\n",
      "mrmr is not installed in the env you are using. This may cause an error in future if you try to use the (missing) lib.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import pandas as pd\n",
    "\n",
    "import sys; sys.path.append('../')\n",
    "from PDE_FIND import *\n",
    "\n",
    "import sys; sys.path.append('../../parametric-discovery/')\n",
    "from best_subset import *\n",
    "from frols import frols\n",
    "from p_linear_regression import PLinearRegression\n",
    "from r_pca import R_pca\n",
    "from pde_diff_new import RPCA\n",
    "from RobustPCA.rpca import RobustPCA\n",
    "\n",
    "import scipy.io as sio\n",
    "from scipy.signal import savgol_filter, butter, filtfilt, wiener\n",
    "from scipy import integrate\n",
    "from scipy.integrate import simpson, trapz, romb\n",
    "import itertools\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import Ridge, BayesianRidge, LinearRegression as SkLinearRegression\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from abess.linear import LinearRegression\n",
    "import pysindy as ps\n",
    "\n",
    "from os.path import join as join_path\n",
    "FIGURE_EXPORT_PATH = \"/Users/pongpisit/Documents/figure_export/\"\n",
    "\n",
    "def evaluate_coefficients(prediected_coeffs):\n",
    "    GROUND = np.array([0.1, -1])\n",
    "    errs = 100*np.abs(GROUND-np.array(prediected_coeffs).flatten())/np.abs(GROUND)\n",
    "    return errs.mean(), errs.std()\n",
    "\n",
    "import torch, sympytorch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sympy import symbols, simplify, lambdify\n",
    "from mathparser import math_eval\n",
    "from varname import nameof\n",
    "from misc import h5file\n",
    "\n",
    "import derivative\n",
    "from tvregdiff import TVRegDiff, tvregdiff, numdiff, pysindydiff, savgol_denoise\n",
    "from functools import partial\n",
    "from findiff import FinDiff\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from tsmoothie.smoother import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9983aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('../Datasets/kuramoto_sivishinky.mat')\n",
    "u = data['uu']\n",
    "x = data['x'][:,0]\n",
    "t = data['tt'][0,:]\n",
    "dt = t[1]-t[0]\n",
    "dx = x[2]-x[1]\n",
    "X, T = np.meshgrid(x, t)\n",
    "XT = np.asarray([X, T]).T\n",
    "\n",
    "assert np.max(x)/32 == np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b219ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "noise_lv = 30\n",
    "un = u + 0.01*noise_lv*u.std()*np.random.randn(u.shape[0],u.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2b41ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# un = np.load(\"./denoised_u_files/KS_noise30_reduced_dctksvdreg.npy\")\n",
    "\n",
    "# un = np.load(\"./denoised_u_files/KS_noise30_reduced_dctV2ksvdreg_21x21.npy\")\n",
    "un = np.load(\"./denoised_u_files/KS_noise30_reduced_dctV2ksvdreg_25x25.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcbb14dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STLSQ model: \n",
      "(x0)' = -0.994 x0_11 + -0.996 x0_1111 + -0.992 x0x0_1\n"
     ]
    }
   ],
   "source": [
    "library_functions = [lambda x: x, lambda x: x * x]\n",
    "library_function_names = [lambda x: x, lambda x: x + x]\n",
    "pde_lib = ps.PDELibrary(\n",
    "    library_functions=library_functions,\n",
    "    function_names=library_function_names,\n",
    "    derivative_order=4,\n",
    "    spatial_grid=x,\n",
    "    is_uniform=True,\n",
    ")\n",
    "\n",
    "print('STLSQ model: ')\n",
    "optimizer = ps.STLSQ(threshold=0.1, alpha=1e-5, normalize_columns=False)\n",
    "model = ps.SINDy(feature_library=pde_lib, optimizer=optimizer)\n",
    "model.fit(np.expand_dims(u, -1), t=dt)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "007b854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Differentiator(ps.BaseDifferentiation):\n",
    "    def __init__(self, diff_name, diff_func_kwargs, \n",
    "                 d=1, axis=1, \n",
    "                 is_uniform=True, periodic=False):\n",
    "        super(Differentiator, self).__init__()\n",
    "        self.diff_name = diff_name\n",
    "        self.diff_func_kwargs = diff_func_kwargs\n",
    "        self.diff_func = getattr(derivative, self.diff_name)(**diff_func_kwargs)\n",
    "        \n",
    "        self.d = d\n",
    "        self.diff = partial(pysindydiff, **{\"diff_method\":self.diff_func, \"order\":self.d})\n",
    "        \n",
    "        # Other info...\n",
    "        self.axis = axis\n",
    "        self.is_uniform = is_uniform\n",
    "        self.periodic = periodic\n",
    "        self.transform = np.vectorize(composite_function(self.diff, lambda _: _, left2right=True), signature=\"(m),(m)->(m)\")\n",
    "\n",
    "    def _differentiate(self, x, t):\n",
    "        in_shape = x.shape\n",
    "        if len(in_shape) == 2: x = np.expand_dims(x, -1) # x should now be 3-dimensional\n",
    "        if isinstance(t, float) and self.is_uniform: \n",
    "            t = np.linspace(0, stop=t*(x.shape[self.axis]-1), num=x.shape[self.axis])\n",
    "        out = []\n",
    "        # wrt to x var\n",
    "        if self.axis == 0:\n",
    "            for i in range(x.shape[-1]):\n",
    "                diff = self.transform(x[:,:,i].T, t).T\n",
    "                out.append(np.expand_dims(diff, axis=-1))\n",
    "        # wrt to time var\n",
    "        elif self.axis == 1:\n",
    "            for i in range(x.shape[-1]):\n",
    "                diff = self.transform(x[:,:,i], t)\n",
    "                out.append(np.expand_dims(diff, axis=-1))\n",
    "        return np.concatenate(out, axis=-1).reshape(in_shape)\n",
    "\n",
    "class FiniteDifferentiator(ps.BaseDifferentiation):\n",
    "    def __init__(self, acc=2, d=1, axis=1, is_uniform=True, periodic=False):\n",
    "        super(FiniteDifferentiator, self).__init__()        \n",
    "        self.acc = 2*(acc//2)\n",
    "        self.d = d\n",
    "        self.axis = axis\n",
    "        self.is_uniform = is_uniform\n",
    "        self.periodic = periodic\n",
    "    def _differentiate(self, x, t):\n",
    "        if self.is_uniform:\n",
    "            if isinstance(t, float): \n",
    "                dt = t\n",
    "            else: \n",
    "                dt = t[1]-t[0]\n",
    "            self.diff = FinDiff(self.axis, dt, self.d, acc=self.acc)\n",
    "        else:\n",
    "            raise NotImplementedError(\"is_uniform=False\")\n",
    "            self.diff = FinDiff(self.axis, self.d, acc=self.acc)\n",
    "        return self.diff(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57631251",
   "metadata": {},
   "outputs": [],
   "source": [
    "### originally from derivative ###\n",
    "## slow ##\n",
    "# diff_name, diff_func_kwargs = \"Kalman\", {'alpha':kalpha}\n",
    "## fast ##\n",
    "# diff_name, diff_func_kwargs = \"FiniteDifference\", {'k':1}\n",
    "# differentiation_method = Differentiator\n",
    "# differentiation_kwargs = {\"diff_name\": diff_name, \"diff_func_kwargs\": diff_func_kwargs}\n",
    "\n",
    "# originally from pysindy\n",
    "# differentiation_method, differentiation_kwargs = ps.SmoothedFiniteDifference, {}\n",
    "\n",
    "# originally from findiff (accurate and fast)\n",
    "differentiation_method, differentiation_kwargs = FiniteDifferentiator, {'acc':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac2a2c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_order = 4\n",
    "weak_pde_lib = ps.WeakPDELibrary(library_functions=[lambda x: x, lambda x: x * x], \n",
    "                                 function_names=[lambda x: x, lambda x: x + x], \n",
    "                                 derivative_order=diff_order, p=diff_order, \n",
    "                                 spatiotemporal_grid=XT, \n",
    "                                 include_bias=False, is_uniform=True, K=10000, # new random K points in every calls to the ps.WeakPDELibrary\n",
    "                                 differentiation_method=differentiation_method, \n",
    "                                 differentiation_kwargs=differentiation_kwargs, \n",
    "                                 cache=True\n",
    "                                )\n",
    "kwargs = {'fit_intercept':False, 'copy_X':True, 'normalize_columns':False}\n",
    "\n",
    "# X_pre = weak_pde_lib.fit_transform(est_u_sol).reshape(-1, len(weak_pde_lib.get_feature_names()))\n",
    "# y_pre = weak_pde_lib.convert_u_dot_integral(est_u_sol)\n",
    "# X_pre, y_pre, fns = ps_features(un, t, weak_pde_lib, kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dbe2eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = L0BNB(max_nonzeros=4, lam=5e-2, is_normal=True, normalize_columns=False, threshold=1e-4) # tune lam จาก (X_pre, y_pre) | ตอนนี้ยังไม่ได้ tune\n",
    "# optimizer = BruteForceRegressor(3)\n",
    "# if feature_library=weak_pde_lib, then just differentiation_method=None is fine.\n",
    "n_ensemble_models = 50\n",
    "model = ps.SINDy(feature_library=weak_pde_lib, optimizer=optimizer, \n",
    "                 differentiation_method=differentiation_method(**differentiation_kwargs), \n",
    "                 cache=True,\n",
    "                 feature_names=['u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dbfd927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u', 'uu', 'u_1', 'u_11', 'u_111', 'u_1111', 'uu_1', 'uuu_1', 'uu_11', 'uuu_11', 'uu_111', 'uuu_111', 'uu_1111', 'uuu_1111']\n"
     ]
    }
   ],
   "source": [
    "model.fit(np.expand_dims(un, -1), t=dt, ensemble=True, library_ensemble=True, n_candidates_to_drop=1, n_models=n_ensemble_models)\n",
    "print(model.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f358a751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_t = (-0.991215 +0.000000i)u_11\n",
      "    + (-0.987916 +0.000000i)u_1111\n",
      "    + (-0.998875 +0.000000i)uu_1\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "X_pre, y_pre = np.squeeze(model.feature_library.cached_xp_full), model.cached_x_dot\n",
    "print_pde(model.get_coef_list()[np.argmin(np.sum((np.squeeze(np.tensordot(X_pre, np.array(model.get_coef_list()).T, axes=([-1], [0])), axis=1)-y_pre)**2, axis=0))].reshape(-1,1), model.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c7fa09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_t = (-0.993022 +0.000000i)u_11\n",
      "    + (-0.995778 +0.000000i)u_1111\n",
      "    + (-0.998724 +0.000000i)uu_1\n",
      "   \n",
      "u_t = (-0.995368 +0.000000i)u_11\n",
      "    + (-0.996953 +0.000000i)u_1111\n",
      "    + (-0.998871 +0.000000i)uu_1\n",
      "    + (0.000392 +0.000000i)uuu_11\n",
      "   \n",
      "u_t = (-0.577216 +0.000000i)uu_1\n",
      "    + (-0.049968 +0.000000i)uuu_11\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "model_results = {}\n",
    "for effective_indices in set([tuple(np.nonzero(model.get_coef_list()[i][0])[0]) \n",
    "                              for i in range(len(model.get_coef_list()))]):\n",
    "    coeff = np.linalg.lstsq(X_pre[:, effective_indices], y_pre, rcond=None)[0]\n",
    "    mse = ((y_pre-X_pre[:, effective_indices]@coeff)**2).mean()\n",
    "    n_terms = len(effective_indices)\n",
    "    if (n_terms > 0) and (n_terms not in model_results or mse < model_results[n_terms][1]):\n",
    "        model_results[n_terms] = effective_indices, mse, coeff\n",
    "        \n",
    "for com in model_results:\n",
    "    effective_indices, _, coeff = model_results[com]\n",
    "    print_pde(coeff, np.array(model.get_feature_names())[list(effective_indices)])\n",
    "    \n",
    "# model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d257da53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = L0BNB(max_nonzeros=5, lam=1e-1, is_normal=False, normalize_columns=False, threshold=1e-4)\n",
    "# optimizer.fit(X_pre, y_pre).coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2edcefe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 5, 6),\n",
       " 0.015537920645042988,\n",
       " array([[-0.99302186],\n",
       "        [-0.99577807],\n",
       "        [-0.99872439]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses = []; optimal_coeff = None\n",
    "all_possible_models = list(itertools.combinations(range(14), 3))\n",
    "for effective_indices in all_possible_models:\n",
    "    coeff = np.linalg.lstsq(X_pre[:, effective_indices], y_pre, rcond=None)[0]\n",
    "    mses.append(((y_pre-X_pre[:, effective_indices]@coeff)**2).mean())\n",
    "optimal_coeff = np.linalg.lstsq(X_pre[:, all_possible_models[np.argmin(mses)]], \n",
    "                                y_pre, rcond=None)[0]\n",
    "all_possible_models[np.argmin(mses)], np.min(mses), optimal_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08247f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4158557680351338"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.abs(optimal_coeff+1)*100).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2747794b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "com = 2, 0.005501994\n",
      "com = 3, 0.0035781963\n",
      "com = 4, 0.004132747\n"
     ]
    }
   ],
   "source": [
    "# com = 3\n",
    "baye_alpha = 1e-6\n",
    "for com in sorted(model_results.keys()):\n",
    "    brr = BayesianRidge(compute_score=True, alpha_1=baye_alpha, alpha_2=baye_alpha)\n",
    "    brr.fit(X_pre[:, model_results[com][0]], y_pre)\n",
    "    print(f\"com = {com},\", np.trace(np.sqrt(brr.sigma_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617a9a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a5f244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e446384",
   "metadata": {},
   "source": [
    "#### WAIC from GPT (need further checking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93a0192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WAIC from GPT\n",
    "# com = 3\n",
    "\n",
    "# # Fit Bayesian Ridge Regression model\n",
    "# regressor = BayesianRidge()\n",
    "# X = X_pre[:, model_results[com][0]]\n",
    "# y = y_pre\n",
    "# regressor.fit(X, y)\n",
    "\n",
    "# # Obtain posterior samples\n",
    "# posterior_samples = np.random.multivariate_normal(regressor.coef_, regressor.sigma_, size=1000)\n",
    "\n",
    "# # Compute log-likelihood\n",
    "# log_likelihoods = -(y - np.dot(X, posterior_samples.T)) ** 2 / (2 * regressor.alpha_)\n",
    "\n",
    "# # Compute pointwise log-sum-exp\n",
    "# pointwise_logsumexp = np.log(np.mean(np.exp(log_likelihoods), axis=1))\n",
    "\n",
    "# # Compute WAIC\n",
    "# waic = -2 * (np.sum(pointwise_logsumexp) - np.sum(np.var(log_likelihoods, axis=1)))\n",
    "# print(\"WAIC:\", waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a2125a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938f770c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa4b0771",
   "metadata": {},
   "source": [
    "## Calculate a weak form of each canidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d42d44e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01072770464374632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.99983724],\n",
       "       [-0.99991587],\n",
       "       [-0.99992506]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=4\n",
    "# Define the derivative:\n",
    "d_dx = FinDiff(0, dx, 1, acc=acc)\n",
    "d_dxx = FinDiff(0, dx, 2, acc=acc)\n",
    "d_dxxxx = FinDiff(0, dx, 4, acc=acc)\n",
    "d_dt = FinDiff(1, dt, 1, acc=acc)\n",
    "\n",
    "coeff = np.linalg.lstsq(np.stack([u*d_dx(u), d_dxx(u), d_dxxxx(u)]).reshape(3, -1).T, \n",
    "                        d_dt(u).reshape(-1,1), rcond=None)[0]\n",
    "print((100*np.abs(coeff+1)).mean())\n",
    "coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5666ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00867587799540844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.00009514],\n",
       "       [-1.00010748],\n",
       "       [-1.00005765]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xf = np.stack([integrate.trapz(d_dxx(u), t, dt, axis=1), \n",
    "               integrate.trapz(d_dxxxx(u), t, dt, axis=1), \n",
    "               integrate.trapz(u*d_dx(u), t, dt, axis=1)]).T\n",
    "yf = integrate.trapz(d_dt(u), t, dt, axis=1).reshape(-1,1)\n",
    "coeff = np.linalg.lstsq(Xf, yf, rcond=None)[0]\n",
    "print((100*np.abs(coeff+1)).mean()) # 0.00867587799540844\n",
    "coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19bbfa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sio.savemat(\"../../PDE_Discovery_Weak_Formulation/Datasets/KS_data_tmp.mat\", \n",
    "#             {'uu': un, 'xx':x, 'tt':t, 'dx':dx, 'dt': dt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5c6f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_poly(x, m, k):\n",
    "    \"\"\"\n",
    "    Polynomial piece of weighting function used to satisfy BC A = d^k/dx^k[(x^2 - 1)^m]\n",
    "    x: independent variable\n",
    "    m: power of base function\n",
    "    k: order of derivative\n",
    "    \"\"\"\n",
    "    a = np.zeros((2*m+1, 1)) # initial coefficient vector\n",
    "    for l in range(m+1):\n",
    "        a[2*l] = ((-1)**(m-l))*np.math.comb(m, l) # set polynomial coefficients\n",
    "    \n",
    "    c = np.zeros((2*m+1, 1)) # final coefficient vector\n",
    "    for n in range(2*m-k+1):\n",
    "        c[n] = a[n+k]*np.math.factorial(n+k)/np.math.factorial(n)\n",
    "    \n",
    "    p = 0\n",
    "    for n in range(2*m-k+1):\n",
    "        p += c[n]*(x**n) # final windowing function\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "746ab677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_full(k, p, x, t):\n",
    "    \"\"\"\n",
    "    Assemble the 1D weight functions into the full weight\n",
    "    k = [kx,ky,kt]: order of derivative(s)\n",
    "    p = [px,py,pt]: exponents of weight polynomials\n",
    "    \"\"\"\n",
    "    if len(k) == 3:\n",
    "        wx = weight_poly(x, p[0], k[0])\n",
    "        wy = weight_poly(x, p[1], k[1])\n",
    "        wt = weight_poly(t, p[2], k[2])\n",
    "        wX, wY, wT = np.meshgrid(wx, wy, wt)\n",
    "        W = wX * wY * wT\n",
    "    elif len(k) == 2:\n",
    "        wx = weight_poly(x, p[0], k[0])\n",
    "        wt = weight_poly(t, p[1], k[1])\n",
    "        wT, wX = np.meshgrid(wt, wx)\n",
    "        W = wX * wT\n",
    "    \n",
    "    return W, wx, wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecec1660",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_weak = un.copy()\n",
    "n_domain = 10000\n",
    "# x_size, t_size = 2**7, 2**7\n",
    "x_size, t_size = 100, 100\n",
    "\n",
    "xsup = np.linspace(-1,1,x_size+1)\n",
    "tsup = np.linspace(-1,1,t_size+1)\n",
    "S_x = 2/(dx*x_size)\n",
    "S_t = 2/(dt*t_size)\n",
    "dx, dt = xsup[1]-xsup[0], tsup[1]-tsup[0]\n",
    "\n",
    "p = [4,3]\n",
    "dA01, _, _ = weight_full([0,1], p, xsup, tsup)\n",
    "dA10, _, _ = weight_full([1,0], p, xsup, tsup)\n",
    "dA20, _, _ = weight_full([2,0], p, xsup, tsup)\n",
    "dA40, _, _ = weight_full([4,0], p, xsup, tsup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f253123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.98819743, -0.98149483, -0.98205128]), 1.6085484422503349)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_weak = []\n",
    "y_weak = []\n",
    "# X_weak_romb = []\n",
    "# y_weak_romb = []\n",
    "for _ in range(n_domain):\n",
    "    ix = np.random.randint(0, len(x)-x_size, size=1)[0] + np.arange(0, x_size+1)\n",
    "    it = np.random.randint(0, len(t)-t_size, size=1)[0] + np.arange(0, t_size+1)\n",
    "    \n",
    "    usup = u_weak[ix, :][:, it]\n",
    "    \n",
    "    f = -(1/2)*(usup**2)*dA10*S_x\n",
    "    f1 = trapz(trapz(f, tsup, dt, 1), xsup, dx, 0)\n",
    "    # f11 = romb(romb(f, dt, 1), dx, 0)\n",
    "    \n",
    "    f = usup*dA20*(S_x**2)\n",
    "    f2 = trapz(trapz(f, tsup, dt, 1), xsup, dx, 0)\n",
    "    # f22 = romb(romb(f, dt, 1), dx, 0)\n",
    "    \n",
    "    f = usup*dA40*(S_x**4)\n",
    "    f3 = trapz(trapz(f, tsup, dt, 1), xsup, dx, 0)\n",
    "    # f33 = romb(romb(f, dt, 1), dx, 0)\n",
    "    \n",
    "    X_weak.append([f1, f2, f3])\n",
    "    # X_weak_romb.append([f11, f22, f33])\n",
    "    \n",
    "    f = -usup*dA01*S_t\n",
    "    f4 = trapz(trapz(f, tsup, dt, 1), xsup, dx, 0)\n",
    "    # f44 = romb(romb(f, dt, 1), dx, 0)\n",
    "    \n",
    "    y_weak.append(f4)\n",
    "    # y_weak_romb.append(f44)\n",
    "    \n",
    "X_weak = np.array(X_weak)\n",
    "y_weak = np.array(y_weak)\n",
    "\n",
    "coeff = np.linalg.lstsq(X_weak, y_weak, rcond=None)[0]\n",
    "(coeff, (np.abs(coeff+1)*100).mean())\n",
    "\n",
    "# X_weak_romb = np.array(X_weak_romb)\n",
    "# y_weak_romb = np.array(y_weak_romb)\n",
    "# coeff = np.linalg.lstsq(X_weak_romb, y_weak_romb, rcond=None)[0]\n",
    "# coeff, (np.abs(coeff+1)*100).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf842b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, q = 5, 4\n",
    "wx, wt = np.meshgrid((xsup**2-1)**p, (tsup**2-1)**q)\n",
    "W = wx*wt\n",
    "\n",
    "# Define the derivative:\n",
    "d_dx = FinDiff(0, xsup[1]-xsup[0], 1)\n",
    "d_dxx = FinDiff(0, xsup[1]-xsup[0], 2)\n",
    "d_dxxxx = FinDiff(0, xsup[1]-xsup[0], 4)\n",
    "d_dt = FinDiff(1, tsup[1]-tsup[0], 1)\n",
    "\n",
    "dA01 = d_dt(W)\n",
    "dA10 = d_dx(W)\n",
    "dA20 = d_dxx(W)\n",
    "dA40 = d_dxxxx(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebaed46",
   "metadata": {},
   "source": [
    "#### Denoised weak form (Savgol V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06636cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_loss = 1e6; best_coeff = None\n",
    "# for ws in trange(3, 33, 2):\n",
    "#     X_weak = []\n",
    "#     y_weak = []\n",
    "#     denoise_u_weak = savgol_filter(u_weak, ws, 2)\n",
    "#     for _ in range(n_domain):\n",
    "#         ix = np.random.randint(0, len(x)-x_size, size=1)[0] + np.arange(0, x_size+1)\n",
    "#         it = np.random.randint(0, len(t)-t_size, size=1)[0] + np.arange(0, t_size+1)\n",
    "\n",
    "#         usup = denoise_u_weak[ix, :][:, it]\n",
    "\n",
    "#         f1 = -(1/2)*(usup**2)*dA10*S_x\n",
    "#         f1 = trapz(trapz(f1, tsup, 1), xsup, 0)\n",
    "\n",
    "#         f2 = usup*dA20*(S_x**2)\n",
    "#         f2 = trapz(trapz(f2, tsup, 1), xsup, 0)\n",
    "\n",
    "#         f3 = usup*dA40*(S_x**4)\n",
    "#         f3 = trapz(trapz(f3, tsup, 1), xsup, 0)\n",
    "\n",
    "#         X_weak.append([f1, f2, f3])\n",
    "\n",
    "#         f4 = -usup*dA01*S_t\n",
    "#         f4 = trapz(trapz(f4, tsup, 1), xsup, 0)\n",
    "#         y_weak.append(f4)\n",
    "\n",
    "#     X_weak = np.array(X_weak)\n",
    "#     y_weak = np.array(y_weak)\n",
    "#     coeff = np.linalg.lstsq(X_weak, y_weak, rcond=None)[0]\n",
    "    \n",
    "#     loss = ((X_weak@coeff-y_weak)**2).mean()\n",
    "#     if loss < min_loss:\n",
    "#         min_loss = loss\n",
    "#         best_coeff = coeff\n",
    "       \n",
    "# min_loss, best_coeff, (np.abs(best_coeff+1)*100).mean() # Nice result (0.2839937497863376)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe22622",
   "metadata": {},
   "source": [
    "#### Denoised weak form (Savgol V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6bca01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Numba: Attempted to fork from a non-main thread, the TBB library may be in an invalid state in the child process.\n",
      "100%|████████████████████████████████████████████████████████████████████| 15/15 [02:17<00:00,  9.18s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.770655590726532e-06,\n",
       " array([-0.99455246, -0.99726875, -0.9999125 ]),\n",
       " 0.27554316548480395)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_loss = 1e6; best_coeff = None\n",
    "for ws in trange(3, 33, 2):\n",
    "    X_weak = []\n",
    "    y_weak = []\n",
    "    for _ in range(n_domain):\n",
    "        ix = np.random.randint(0, len(x)-x_size, size=1)[0] + np.arange(0, x_size+1)\n",
    "        it = np.random.randint(0, len(t)-t_size, size=1)[0] + np.arange(0, t_size+1)\n",
    "        \n",
    "        usup = savgol_filter(u_weak[ix, :][:, it], ws, 2)\n",
    "\n",
    "        f1 = -(1/2)*(usup**2)*dA10*S_x\n",
    "        f1 = trapz(trapz(f1, tsup, dt, 1), xsup, dx, 0)\n",
    "#         f1 = romb(romb(f1, dt, 1), dx, 0)\n",
    "\n",
    "        f2 = usup*dA20*(S_x**2)\n",
    "        f2 = trapz(trapz(f2, tsup, dt, 1), xsup, dx, 0)\n",
    "#         f2 = romb(romb(f2, dt, 1), dx, 0)\n",
    "\n",
    "        f3 = usup*dA40*(S_x**4)\n",
    "        f3 = trapz(trapz(f3, tsup, dt, 1), xsup, dx, 0)\n",
    "#         f3 = romb(romb(f3, dt, 1), dx, 0)\n",
    "\n",
    "        X_weak.append([f1, f2, f3])\n",
    "\n",
    "        f4 = -usup*dA01*S_t\n",
    "        f4 = trapz(trapz(f4, tsup, dt, 1), xsup, dx, 0)\n",
    "#         f4 = romb(romb(f4, dt, 1), dx, 0)\n",
    "        y_weak.append(f4)\n",
    "\n",
    "    X_weak = np.array(X_weak)\n",
    "    y_weak = np.array(y_weak)\n",
    "    coeff = np.linalg.lstsq(X_weak, y_weak, rcond=None)[0]\n",
    "    \n",
    "    loss = ((X_weak@coeff-y_weak)**2).mean()\n",
    "    if loss < min_loss:\n",
    "        min_loss = loss\n",
    "        best_coeff = coeff\n",
    "\n",
    "# Maybe do simulation next?\n",
    "min_loss, best_coeff, (np.abs(best_coeff+1)*100).mean() # Nice result (0.28399369505097694)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62b4bd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 , 0.11,\n",
       "       0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21, 0.22,\n",
       "       0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32, 0.33,\n",
       "       0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43, 0.44,\n",
       "       0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54, 0.55,\n",
       "       0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65, 0.66,\n",
       "       0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77,\n",
       "       0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88,\n",
       "       0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = 0.01\n",
    "hyperparameter_val_range = np.arange(step, 1, step)\n",
    "hyperparameter_val_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9aa4df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 99/99 [07:32<00:00,  4.57s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.7701685183580024e-06,\n",
       " array([-0.9944473 , -0.99703951, -0.99960276]),\n",
       " 0.2970143422940182)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_loss = 1e6; best_coeff = None\n",
    "for hyperparameter_val in tqdm(hyperparameter_val_range):\n",
    "    X_weak = []\n",
    "    y_weak = []\n",
    "    denoise_u_weak = filtfilt(*butter(2, hyperparameter_val), u_weak)\n",
    "    for _ in range(n_domain):\n",
    "        ix = np.random.randint(0, len(x)-x_size, size=1)[0] + np.arange(0, x_size+1)\n",
    "        it = np.random.randint(0, len(t)-t_size, size=1)[0] + np.arange(0, t_size+1)\n",
    "        \n",
    "        usup = denoise_u_weak[ix, :][:, it]\n",
    "\n",
    "        f1 = -(1/2)*(usup**2)*dA10*S_x\n",
    "        f1 = trapz(trapz(f1, tsup, dt, 1), xsup, dx, 0)\n",
    "#         f1 = romb(romb(f1, dt, 1), dx, 0)\n",
    "\n",
    "        f2 = usup*dA20*(S_x**2)\n",
    "        f2 = trapz(trapz(f2, tsup, dt, 1), xsup, dx, 0)\n",
    "#         f2 = romb(romb(f2, dt, 1), dx, 0)\n",
    "\n",
    "        f3 = usup*dA40*(S_x**4)\n",
    "        f3 = trapz(trapz(f3, tsup, dt, 1), xsup, dx, 0)\n",
    "#         f3 = romb(romb(f3, dt, 1), dx, 0)\n",
    "\n",
    "        X_weak.append([f1, f2, f3])\n",
    "\n",
    "        f4 = -usup*dA01*S_t\n",
    "        f4 = trapz(trapz(f4, tsup, dt, 1), xsup, dx, 0)\n",
    "#         f4 = romb(romb(f4, dt, 1), dx, 0)\n",
    "        y_weak.append(f4)\n",
    "\n",
    "    X_weak = np.array(X_weak)\n",
    "    y_weak = np.array(y_weak)\n",
    "    coeff = np.linalg.lstsq(X_weak, y_weak, rcond=None)[0]\n",
    "    \n",
    "    loss = ((X_weak@coeff-y_weak)**2).mean()\n",
    "    if loss < min_loss:\n",
    "        min_loss = loss\n",
    "        best_coeff = coeff\n",
    "\n",
    "# Maybe do simulation next?\n",
    "min_loss, best_coeff, (np.abs(best_coeff+1)*100).mean() # Nice result (0.31068650078021803)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf08c61",
   "metadata": {},
   "source": [
    "#### Denoised weak form (Wiener, Current best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a84fa981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 30/30 [07:31<00:00, 15.05s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.001980916828565e-06,\n",
       " array([-1.00137709, -0.99922417, -1.00434196]),\n",
       " 0.2164960913560813)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_loss = 1e6; best_coeff = None\n",
    "for ws in trange(3, 33, 1):\n",
    "    X_weak = []\n",
    "    y_weak = []\n",
    "    \n",
    "    for _ in range(n_domain):\n",
    "        ix = np.random.randint(0, len(x)-x_size, size=1)[0] + np.arange(0, x_size+1)\n",
    "        it = np.random.randint(0, len(t)-t_size, size=1)[0] + np.arange(0, t_size+1)\n",
    "        \n",
    "        usup = wiener(u_weak[ix, :][:, it], ws)\n",
    "\n",
    "        f1 = -(1/2)*(usup**2)*dA10*S_x\n",
    "        f1 = trapz(trapz(f1, tsup, dt, 1), xsup, dx, 0)\n",
    "#         f1 = romb(romb(f1, dt, 1), dx, 0)\n",
    "\n",
    "        f2 = usup*dA20*(S_x**2)\n",
    "        f2 = trapz(trapz(f2, tsup, dt, 1), xsup, dx, 0)\n",
    "#         f2 = romb(romb(f2, dt, 1), dx, 0)\n",
    "\n",
    "        f3 = usup*dA40*(S_x**4)\n",
    "        f3 = trapz(trapz(f3, tsup, dt, 1), xsup, dx, 0)\n",
    "#         f3 = romb(romb(f3, dt, 1), dx, 0)\n",
    "\n",
    "        X_weak.append([f1, f2, f3])\n",
    "\n",
    "        f4 = -usup*dA01*S_t\n",
    "        f4 = trapz(trapz(f4, tsup, dt, 1), xsup, dx, 0)\n",
    "#         f4 = romb(romb(f4, dt, 1), dx, 0)\n",
    "        y_weak.append(f4)\n",
    "\n",
    "    X_weak = np.array(X_weak)\n",
    "    y_weak = np.array(y_weak)\n",
    "    coeff = np.linalg.lstsq(X_weak, y_weak, rcond=None)[0]\n",
    "    \n",
    "    loss = ((X_weak@coeff-y_weak)**2).mean()\n",
    "    if loss < min_loss:\n",
    "        min_loss = loss\n",
    "        best_coeff = coeff\n",
    "\n",
    "# Maybe do simulation next?\n",
    "# Nice result (0.25734593832127023, 0.21403537689738497)\n",
    "min_loss, best_coeff, (np.abs(best_coeff+1)*100).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c300350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pysr]",
   "language": "python",
   "name": "conda-env-pysr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
