{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f6dbc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat, savemat\n",
    "from scipy.signal import savgol_filter, butter, filtfilt, wiener\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess as sm_lowess\n",
    "from tsmoothie.smoother import *\n",
    "\n",
    "import torch\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from DeepAE import DeepAutoencoder\n",
    "from lightning_helper import *\n",
    "\n",
    "from skimage.util import img_as_float\n",
    "from sklearn.feature_extraction.image import extract_patches_2d, reconstruct_from_patches_2d\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning\n",
    "from ksvd import ApproximateKSVD\n",
    "from spmimage.decomposition import KSVD, generate_dct_dictionary, generate_dct_dict\n",
    "\n",
    "import sys; sys.path.insert(0, \"../\")\n",
    "from misc import yaml_load\n",
    "from savgol import *\n",
    "from savitzky_golay_werrors import savgol_filter_werror\n",
    "\n",
    "def l21shrink(epsilon, x):\n",
    "    output = x.copy()\n",
    "    norm = np.linalg.norm(x, ord=2, axis=0)\n",
    "    for i in range(x.shape[1]):\n",
    "        if norm[i] > epsilon:\n",
    "            for j in range(x.shape[0]):\n",
    "                output[j,i] = x[j,i] - epsilon * x[j,i] / norm[i]\n",
    "        else:\n",
    "            output[:,i] = 0.\n",
    "    return output\n",
    "\n",
    "main_seed = 0\n",
    "\n",
    "import pathlib\n",
    "def add_patchsize_signature(file_path, ps):\n",
    "    sig = str(ps[0])+'x'+str(ps[1])\n",
    "    pl = pathlib.Path(file_path)\n",
    "    ext = pl.name.split('.')[-1]\n",
    "    newname = pl.name.split('.')[0]+'_'+sig+'.'+ext\n",
    "    return os.path.join(str(pl.parent.absolute()), newname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c27034b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded...\n"
     ]
    }
   ],
   "source": [
    "fconfig = yaml_load(\"./ksvd_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82761008",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('../Datasets/burgers.mat')\n",
    "u = (data['usol']).real\n",
    "x = (data['x'][0]).real\n",
    "t = (data['t'][:,0]).real\n",
    "Xd, Td = np.meshgrid(x, t)\n",
    "\n",
    "np.random.seed(0)\n",
    "noise_lv = 30\n",
    "noise = 0.01*np.abs(noise_lv)*(u.std())*np.random.randn(u.shape[0], u.shape[1])\n",
    "\n",
    "un = u+noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7a4cd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8)\n"
     ]
    }
   ],
   "source": [
    "div = 20; axis = 1 # div = 10, 15, 20*\n",
    "patch_size = (int(256//div), int(101//div))\n",
    "avg_patch_size = (patch_size[0]+patch_size[1])//2\n",
    "patch_size = (avg_patch_size, avg_patch_size)\n",
    "# patch_size = (8, 8)\n",
    "print(patch_size)\n",
    "\n",
    "un_img = img_as_float(un)\n",
    "patches = extract_patches_2d(un_img, patch_size)\n",
    "\n",
    "signals = patches.reshape(patches.shape[0], -1)\n",
    "mean = np.mean(signals, axis=axis)\n",
    "mean = mean[:, np.newaxis] if axis > 0 else mean\n",
    "std = np.std(signals, axis=axis)\n",
    "std = std[:, np.newaxis] if axis > 0 else mean\n",
    "# signals = (signals-mean)/std\n",
    "signals = signals-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "480e410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(main_seed)\n",
    "# 64, 50, 40, 32, 16, 8 (64 was not so good | max should be 40?)\n",
    "n_components = 32; alpha = 1; batch_size = 3\n",
    "transform_n_nonzero_coefs = None # 1\n",
    "mode = 'dctksvd_reg' # ksvd, dictionary_learning, spm_ksvd, spm_dctksvd, ksvd_reg\n",
    "# n_components = fconfig[\"n_components\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecafe00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = \"/Users/pongpisit/Desktop/research/ompbox10/Burgers_sig.mat\"\n",
    "# if patch_size[0] == patch_size[1]: file_name = add_patchsize_signature(file_name, patch_size)\n",
    "# mdict = {'sig':signals, 'D0':generate_dct_dict(n_components, (patch_size[0], patch_size[1])).T}\n",
    "# print(file_name)\n",
    "# savemat(file_name, mdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63949412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dctksvd_reg\n",
      "/Users/pongpisit/Desktop/research/PDE-FIND/Denoise/dctksvdV2_reg_out_8x8.mat\n"
     ]
    }
   ],
   "source": [
    "print(mode)\n",
    "\n",
    "if mode == 'ksvd':\n",
    "    ksvd = ApproximateKSVD(n_components=n_components, max_iter=10, \n",
    "                           transform_n_nonzero_coefs=transform_n_nonzero_coefs)\n",
    "    dictionary = ksvd.fit(signals).components_\n",
    "    gamma = ksvd.transform(signals)\n",
    "\n",
    "elif mode == 'spm_ksvd':\n",
    "    method = 'approximate' # 'normal'\n",
    "    ksvd = KSVD(n_components=n_components, max_iter=20, \n",
    "                transform_n_nonzero_coefs=transform_n_nonzero_coefs, \n",
    "                method=method, dict_init=None)\n",
    "    dictionary = ksvd.fit(signals).components_\n",
    "    gamma = ksvd.transform(signals)\n",
    "    \n",
    "elif mode == 'ksvd_reg':\n",
    "    # (s=1.5, reg=0.05, iters=20)\n",
    "    # save('/Users/pongpisit/Desktop/research/PDE-FIND/Denoise/ksvd_reg_out.mat', 'Df', 'Xf');\n",
    "    filename = \"ksvd_reg_out.mat\"\n",
    "    ksvd = KSVD(n_components=n_components, max_iter=20, \n",
    "                transform_n_nonzero_coefs=transform_n_nonzero_coefs)\n",
    "    ksvd.components_ = loadmat(filename)['Df'].T\n",
    "    dictionary = ksvd.components_\n",
    "    gamma = ksvd.transform(signals)\n",
    "    \n",
    "elif mode == 'dctksvd_reg':\n",
    "    # (s=1.5, reg=0.05, iters=20)\n",
    "    # save('/Users/pongpisit/Desktop/research/PDE-FIND/Denoise/ksvd_reg_out.mat', 'Df', 'Xf');\n",
    "    filename = \"dctksvdV2_reg_out.mat\"\n",
    "    if patch_size[0] == patch_size[1]: filename = add_patchsize_signature(filename, patch_size)\n",
    "    print(filename)\n",
    "    ksvd = KSVD(n_components=n_components, max_iter=20, \n",
    "                transform_n_nonzero_coefs=transform_n_nonzero_coefs)\n",
    "    ksvd.components_ = loadmat(filename)['Df'].T\n",
    "    dictionary = ksvd.components_\n",
    "    gamma = ksvd.transform(signals)\n",
    "    \n",
    "elif mode == 'spm_dctksvd':\n",
    "    method = 'approximate' # 'normal'\n",
    "    ksvd = KSVD(n_components=n_components, max_iter=1000, \n",
    "                transform_n_nonzero_coefs=transform_n_nonzero_coefs, \n",
    "                method=method, dict_init=generate_dct_dict(n_components, (patch_size[0], patch_size[1])))\n",
    "#     if patch_size[0] == patch_size[1]:\n",
    "#         ksvd = KSVD(n_components=n_components, max_iter=20, \n",
    "#                     transform_n_nonzero_coefs=transform_n_nonzero_coefs, \n",
    "#                     method=method, \n",
    "#                     dict_init=generate_dct_dictionary(n_components, max(patch_size)))\n",
    "    dictionary = ksvd.fit(signals).components_\n",
    "    gamma = ksvd.transform(signals)\n",
    "\n",
    "elif mode == 'dictionary_learning':\n",
    "    transform_algorithms = ['omp', 'lars']\n",
    "    ksvd = MiniBatchDictionaryLearning(n_components=n_components, alpha=alpha, \n",
    "                                       batch_size=batch_size, fit_algorithm='cd', \n",
    "                                       transform_algorithm=transform_algorithms[1], \n",
    "                                       transform_n_nonzero_coefs=None, tol=1e-3)\n",
    "    dictionary = ksvd.fit(signals).components_\n",
    "    gamma = ksvd.transform(signals)\n",
    "\n",
    "# reduced_un = std*gamma.dot(dictionary)+mean\n",
    "reduced_un = gamma.dot(dictionary)+mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87880871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003159897495617633"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_un = reconstruct_from_patches_2d(reduced_un.reshape(patches.shape), un_img.shape)\n",
    "reduced_un = np.array(reduced_un).astype(np.float32)\n",
    "# 0.0003902020972793252, 0.00034107647454082054, 0.0003338082126143274(DCT V2), 0.0003159897495617633(8x8)\n",
    "((reduced_un-u)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e7e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"../RDAE_data/{mode}/none/transform_n_nonzero_coefs_none/burgers_dictlearn_denoised{noise_lv}_components{n_components}.npy\"\n",
    "if patch_size[0] == patch_size[1]: file_name = add_patchsize_signature(file_name, patch_size)\n",
    "print(file_name)\n",
    "np.save(file_name, reduced_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fced25a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86412f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f22acde",
   "metadata": {},
   "outputs": [],
   "source": [
    "((wiener(reduced_un.T, 5).T-u)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d5725",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"../RDAE_data/{mode}/wiener/transform_n_nonzero_coefs_none/burgers_dictlearn_denoised{noise_lv}_components{n_components}.npy\"\n",
    "file_name = add_patchsize_signature(file_name, patch_size)\n",
    "print(file_name)\n",
    "np.save(file_name, wiener(reduced_un.T, 5).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85f924d",
   "metadata": {},
   "source": [
    "#### Experimental code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4468c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered = np.vstack([sm_lowess(reduced_un[:, i].flatten(), x, frac=0.05)[:, 1] \n",
    "#                       for i in range(len(t))]).T\n",
    "\n",
    "# making more sense?\n",
    "# filtered = np.vstack([sm_lowess(reduced_un[i, :].flatten(), t, frac=0.2)[:, 1] \n",
    "#                       for i in range(len(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101d3fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((filtered-u)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2baadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cn = 5e-3\n",
    "# smoother = KalmanSmoother(component='level_trend', component_noise={'level':cn, 'trend':cn})\n",
    "# sin = np.sin(np.linspace(0, 3*np.pi, 1000))\n",
    "# sinn = sin + np.random.randn(1000)\n",
    "# denoised = smoother.smooth(sinn).smooth_data.flatten()\n",
    "# plt.plot(sinn)\n",
    "# plt.plot(denoised)\n",
    "# plt.plot(sin)\n",
    "# plt.show()\n",
    "# ((denoised-sin)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee684e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((iterative_savgol_filter(reduced_un)-u)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e4b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = f\"../RDAE_data/{mode}/savgol/transform_n_nonzero_coefs_none/burgers_dictlearn_denoised{noise_lv}_components{n_components}.npy\"\n",
    "# print(file_name)\n",
    "# np.save(file_name, iterative_savgol_filter(reduced_un))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07508427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters\n",
    "ws = 5\n",
    "delta = 10\n",
    "max_window_size = len(reduced_un[0, :])//2+1  # Maximum allowed window size\n",
    "poly_order = 2  # Polynomial order\n",
    "threshold = 1e-4  # Threshold for convergence\n",
    "\n",
    "# Apply iterative smoothing\n",
    "smoothed_data = iterative_savgol_gpt(reduced_un, ws, poly_order, delta, \n",
    "                                     max_window_size, threshold)\n",
    "\n",
    "# Print the smoothed data\n",
    "print(((smoothed_data-u)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66db46d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dysmho = DySMHO(reduced_un, div=2)\n",
    "denoised = dysmho.smooth(window_size=9) # 1-10\n",
    "((denoised-u)**2).mean(), dysmho.best_window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c9797",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised = np.vstack([savgol_filter_werror(reduced_un[i, :], window_length=dysmho.best_window_size, degree=2, \n",
    "                                           error=np.ones((len(x)), np.float32)*1e-1) for i in range(len(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa12e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "((denoised-u)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007e857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"../RDAE_data/{mode}/savgol/transform_n_nonzero_coefs_none/burgers_dictlearn_denoised{noise_lv}_components{n_components}.npy\"\n",
    "if patch_size[0] == patch_size[1]: file_name = add_patchsize_signature(file_name, patch_size)\n",
    "print(file_name)\n",
    "np.save(file_name, denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c0e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c933f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e07a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38e89c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# operate smoothing\n",
    "reduced_un_c = reduced_un.copy()\n",
    "smoother_name = 'kalman' # lowess, kalman, gaussian, 'none' (all axis=-1) | filtfilt (axis=0)\n",
    "reduced_un = reduced_un.T if smoother_name == 'filtfilt' else reduced_un\n",
    "\n",
    "if smoother_name != 'none':\n",
    "    if smoother_name == 'lowess': \n",
    "        sf = 0.2 # ksvd (prefered)\n",
    "        sf = sf/2 if mode == 'dictionary_learning' else sf\n",
    "        smoother = LowessSmoother(smooth_fraction=sf, iterations=1)\n",
    "        reduced_un = smoother.smooth(reduced_un).smooth_data\n",
    "    elif smoother_name == 'kalman':\n",
    "        cn = 0.005 # ksvd (prefered)\n",
    "        cn = cn*2 if mode == 'dictionary_learning' else cn\n",
    "        smoother = KalmanSmoother(component='level_trend', component_noise={'level':cn, 'trend':cn})\n",
    "        reduced_un = smoother.smooth(reduced_un).smooth_data\n",
    "    elif smoother_name == 'gaussian':\n",
    "        smoother = GaussianSmoother(n_knots=10, sigma=1.0)\n",
    "        reduced_un = smoother.smooth(reduced_un).smooth_data\n",
    "    elif smoother_name == 'filtfilt':\n",
    "        reduced_un = filtfilt(*butter(2, 0.1), reduced_un)\n",
    "        \n",
    "reduced_un = reduced_un.T if smoother_name == 'filtfilt' else reduced_un\n",
    "print(((reduced_un-u)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54f804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = f\"../RDAE_data/{mode}/{smoother_name}/transform_n_nonzero_coefs_none/burgers_dictlearn_denoised{noise_lv}_components{n_components}.npy\"\n",
    "# print(file_name)\n",
    "# np.save(file_name, reduced_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b15cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(Xd, Td, u.T, levels=10)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895cd38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(Xd, Td, un.T, levels=10)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(Xd, Td, reduced_un.T, levels=10)\n",
    "plt.colorbar()\n",
    "plt.show() # 0.00011357113834071512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16621f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f241b503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38efc149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# : stays at the axis to which denoising function applies\n",
    "v1 = np.vstack([filtfilt(*butter(2, 0.1), reduced_un[:, i]) for i in range(len(t))]).T\n",
    "v2 = np.vstack([filtfilt(*butter(2, 0.1), reduced_un[i, :]) for i in range(len(x))])\n",
    "v3 = filtfilt(*butter(2, 0.1), reduced_un)\n",
    "assert np.abs(v2-v3).sum() == 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pysr]",
   "language": "python",
   "name": "conda-env-pysr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
